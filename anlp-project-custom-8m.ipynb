{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9872633,"sourceType":"datasetVersion","datasetId":6060712}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:09:41.729134Z","iopub.execute_input":"2024-11-19T12:09:41.729961Z","iopub.status.idle":"2024-11-19T12:09:41.739208Z","shell.execute_reply.started":"2024-11-19T12:09:41.729891Z","shell.execute_reply":"2024-11-19T12:09:41.738418Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/vocab-dict-final/vocab_dict_v2/dataset_dict.json\n/kaggle/input/vocab-dict-final/vocab_dict_v2/validation/state.json\n/kaggle/input/vocab-dict-final/vocab_dict_v2/validation/dataset_info.json\n/kaggle/input/vocab-dict-final/vocab_dict_v2/validation/data-00000-of-00001.arrow\n/kaggle/input/vocab-dict-final/vocab_dict_v2/train/state.json\n/kaggle/input/vocab-dict-final/vocab_dict_v2/train/dataset_info.json\n/kaggle/input/vocab-dict-final/vocab_dict_v2/train/data-00000-of-00001.arrow\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install datasets\n!pip install -q -U google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:09:42.951183Z","iopub.execute_input":"2024-11-19T12:09:42.951972Z","iopub.status.idle":"2024-11-19T12:10:09.909214Z","shell.execute_reply.started":"2024-11-19T12:09:42.951938Z","shell.execute_reply":"2024-11-19T12:10:09.908018Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport time\nimport wandb\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch.nn as nn\nfrom torch.utils import data\nfrom datasets import load_dataset\nfrom transformers import GPT2TokenizerFast\nfrom kaggle_secrets import UserSecretsClient\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom google.generativeai.types import RequestOptions\nimport google.generativeai as gemini_ai\nfrom google.api_core import retry\nimport json\nfrom collections import Counter\nimport random\nimport nltk\nimport re\nfrom datasets import Dataset, DatasetDict\nfrom tokenizers import Tokenizer, models, normalizers, pre_tokenizers, decoders, trainers\nfrom transformers import PreTrainedTokenizerFast\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:09.911583Z","iopub.execute_input":"2024-11-19T12:10:09.912410Z","iopub.status.idle":"2024-11-19T12:10:16.392877Z","shell.execute_reply.started":"2024-11-19T12:10:09.912357Z","shell.execute_reply":"2024-11-19T12:10:16.391960Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"user_secrets = UserSecretsClient()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:16.394000Z","iopub.execute_input":"2024-11-19T12:10:16.394485Z","iopub.status.idle":"2024-11-19T12:10:16.398580Z","shell.execute_reply.started":"2024-11-19T12:10:16.394457Z","shell.execute_reply":"2024-11-19T12:10:16.397614Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"wandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:21.608790Z","iopub.execute_input":"2024-11-19T12:10:21.609625Z","iopub.status.idle":"2024-11-19T12:10:21.839319Z","shell.execute_reply.started":"2024-11-19T12:10:21.609590Z","shell.execute_reply":"2024-11-19T12:10:21.838659Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"wandb.login(key=wandb_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:22.805162Z","iopub.execute_input":"2024-11-19T12:10:22.806009Z","iopub.status.idle":"2024-11-19T12:10:24.373759Z","shell.execute_reply.started":"2024-11-19T12:10:22.805971Z","shell.execute_reply":"2024-11-19T12:10:24.372943Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"gemini_api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:24.375280Z","iopub.execute_input":"2024-11-19T12:10:24.376386Z","iopub.status.idle":"2024-11-19T12:10:24.522502Z","shell.execute_reply.started":"2024-11-19T12:10:24.376344Z","shell.execute_reply":"2024-11-19T12:10:24.521940Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"gemini_ai.configure(api_key=gemini_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:24.732067Z","iopub.execute_input":"2024-11-19T12:10:24.732312Z","iopub.status.idle":"2024-11-19T12:10:24.736395Z","shell.execute_reply.started":"2024-11-19T12:10:24.732288Z","shell.execute_reply":"2024-11-19T12:10:24.735462Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:25.948037Z","iopub.execute_input":"2024-11-19T12:10:25.948377Z","iopub.status.idle":"2024-11-19T12:10:25.974493Z","shell.execute_reply.started":"2024-11-19T12:10:25.948342Z","shell.execute_reply":"2024-11-19T12:10:25.973464Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"config = {\n    \"BLOCK_SIZE\": 128,\n    \"EMB_SIZE\": 256,\n    \"N_ATTENTION_HEADS\": 8,\n    \"N_DECODER_BLOCKS\": 4,\n    \"VOCAB_SIZE\": 10000,\n    \"MAX_OUT_TOKENS\": 200,\n    \"EVAL_ITER\": 100,\n    \"LR\": 3e-4,\n    \"BATCH_SIZE\": 32,\n    \"EPOCHS\": 5,\n    \"PATIENCE\": 3,\n    \"MODEL_NAME\": \"custom-8M\",\n    \"WORKING_DIR\": \"/kaggle/working\",\n    \"DEVICE\": 'cuda' if torch.cuda.is_available() else 'cpu'\n}\nassert config['EMB_SIZE'] % config['N_ATTENTION_HEADS'] == 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:27.751877Z","iopub.execute_input":"2024-11-19T12:10:27.752241Z","iopub.status.idle":"2024-11-19T12:10:27.757268Z","shell.execute_reply.started":"2024-11-19T12:10:27.752212Z","shell.execute_reply":"2024-11-19T12:10:27.756424Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"wandb.init(\n    project='custom-8M',\n    config=config\n)\ntext_table = wandb.Table(columns=['epoch', 'loss', 'predicted text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:30.833929Z","iopub.execute_input":"2024-11-19T12:10:30.834273Z","iopub.status.idle":"2024-11-19T12:10:33.739189Z","shell.execute_reply.started":"2024-11-19T12:10:30.834245Z","shell.execute_reply":"2024-11-19T12:10:33.738469Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddharthdhara17\u001b[0m (\u001b[33mdhara\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112807522221779, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e8b60c6b3274b128537dee35ce386e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241119_121030-lp5yrm4d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dhara/custom-8M/runs/lp5yrm4d' target=\"_blank\">dutiful-sponge-8</a></strong> to <a href='https://wandb.ai/dhara/custom-8M' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dhara/custom-8M' target=\"_blank\">https://wandb.ai/dhara/custom-8M</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dhara/custom-8M/runs/lp5yrm4d' target=\"_blank\">https://wandb.ai/dhara/custom-8M/runs/lp5yrm4d</a>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"load_model = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:33.777268Z","iopub.execute_input":"2024-11-19T12:10:33.777512Z","iopub.status.idle":"2024-11-19T12:10:33.781986Z","shell.execute_reply.started":"2024-11-19T12:10:33.777487Z","shell.execute_reply":"2024-11-19T12:10:33.781247Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"load_df = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:33.782998Z","iopub.execute_input":"2024-11-19T12:10:33.783305Z","iopub.status.idle":"2024-11-19T12:10:33.795728Z","shell.execute_reply.started":"2024-11-19T12:10:33.783270Z","shell.execute_reply":"2024-11-19T12:10:33.795134Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"dataset = load_dataset(\"roneneldan/TinyStories\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:35.795083Z","iopub.execute_input":"2024-11-19T12:10:35.795731Z","iopub.status.idle":"2024-11-19T12:10:49.993163Z","shell.execute_reply.started":"2024-11-19T12:10:35.795698Z","shell.execute_reply":"2024-11-19T12:10:49.992454Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e3311844d1b404d94f3677dcba4adc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00004-2d5a1467fff1081b.parquet:   0%|          | 0.00/249M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"110f66337d514358bcf194b700d37b86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00001-of-00004-5852b56a2bd28fd9.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d6a9350ce4445dfa1da1b218ff40b1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00002-of-00004-a26307300439e943.parquet:   0%|          | 0.00/246M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e16dd1240e4d46778cb78a7315a7be3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00003-of-00004-d243063613e5a057.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ace0b04a59e42e4bba950cf8cd6075e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-869c898b519ad725.parquet:   0%|          | 0.00/9.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"346026627e5f404aad366f423ef4d109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bb5fc3dfc0f4a27a51c4a0c794d3aed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5211d855c0ad4baebf32348554df80f0"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"loaded_vocab_dataset = DatasetDict.load_from_disk('/kaggle/input/vocab-dict-final/vocab_dict_v2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:50.018750Z","iopub.execute_input":"2024-11-19T12:10:50.019013Z","iopub.status.idle":"2024-11-19T12:10:50.159376Z","shell.execute_reply.started":"2024-11-19T12:10:50.018987Z","shell.execute_reply":"2024-11-19T12:10:50.158759Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"custom_vocab = loaded_vocab_dataset['train']['word']\nnew_vocab_size = len(custom_vocab)\nprint(new_vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:50.185560Z","iopub.execute_input":"2024-11-19T12:10:50.185798Z","iopub.status.idle":"2024-11-19T12:10:54.377128Z","shell.execute_reply.started":"2024-11-19T12:10:50.185773Z","shell.execute_reply":"2024-11-19T12:10:54.376156Z"}},"outputs":[{"name":"stdout","text":"9996\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"custom_vocab_dict = {word: idx for idx, word in enumerate(custom_vocab)}\nif \"[UNK]\" not in custom_vocab_dict:\n    print(\"Adding [UNK] token to the vocabulary.\")\n    custom_vocab_dict[\"[UNK]\"] = len(custom_vocab_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:54.406942Z","iopub.execute_input":"2024-11-19T12:10:54.407246Z","iopub.status.idle":"2024-11-19T12:10:55.231949Z","shell.execute_reply.started":"2024-11-19T12:10:54.407210Z","shell.execute_reply":"2024-11-19T12:10:55.230999Z"}},"outputs":[{"name":"stdout","text":"Adding [UNK] token to the vocabulary.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"used_dataset_size = 100000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:55.234879Z","iopub.execute_input":"2024-11-19T12:10:55.235298Z","iopub.status.idle":"2024-11-19T12:10:56.239442Z","shell.execute_reply.started":"2024-11-19T12:10:55.235247Z","shell.execute_reply":"2024-11-19T12:10:56.237476Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"sampled_dataset = dataset['train'].train_test_split(train_size=0.8, test_size=0.2)\ntrain_dataset, val_dataset = sampled_dataset['train'].select(range(int(0.8 * used_dataset_size))), sampled_dataset['test'].select(range(int(0.2 * used_dataset_size)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:56.270498Z","iopub.execute_input":"2024-11-19T12:10:56.271986Z","iopub.status.idle":"2024-11-19T12:10:57.025181Z","shell.execute_reply.started":"2024-11-19T12:10:56.271945Z","shell.execute_reply":"2024-11-19T12:10:57.024258Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class GPT2FromScratch(nn.Module):\n    def __init__(self, config):\n        super(GPT2FromScratch, self).__init__()\n        self.embeddings = nn.Embedding(config[\"VOCAB_SIZE\"], config[\"EMB_SIZE\"])\n        self.blocks = nn.ModuleList([\n            nn.TransformerEncoderLayer(\n                d_model=config[\"EMB_SIZE\"],\n                nhead=config[\"N_ATTENTION_HEADS\"],\n                dim_feedforward=config[\"EMB_SIZE\"] * 4,\n                activation='gelu'\n            )\n            for _ in range(config[\"N_DECODER_BLOCKS\"])\n        ])\n        self.final_norm = nn.LayerNorm(config[\"EMB_SIZE\"])\n        self.head = nn.Linear(config[\"EMB_SIZE\"], config[\"VOCAB_SIZE\"])\n        self.block_size = config.get(\"BLOCK_SIZE\", 128)  # Define block size for context\n\n    def forward(self, x):\n        x = self.embeddings(x)\n        for block in self.blocks:\n            x = block(x)\n        x = self.final_norm(x)\n        return self.head(x)\n\n    def generate(self, idx, max_new_tokens):\n        self.eval()  # Ensure the model is in evaluation mode\n        for _ in range(max_new_tokens):\n            # Crop idx to the last block_size tokens\n            idx_cond = idx[:, -self.block_size:]\n            # Get the predictions\n            logits = self(idx_cond)  # Only use logits (ignore loss)\n            # Focus only on the last time step\n            logits = logits[:, -1, :]  # (B, VOCAB_SIZE)\n            # Apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1)  # (B, VOCAB_SIZE)\n            # Sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n            # Append the sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n        return idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:10:57.026312Z","iopub.execute_input":"2024-11-19T12:10:57.026586Z","iopub.status.idle":"2024-11-19T12:10:57.035662Z","shell.execute_reply.started":"2024-11-19T12:10:57.026560Z","shell.execute_reply":"2024-11-19T12:10:57.034808Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# # LoRA Layer Integration for Low-Rank Adaptation on the final layer\n\n# class LoRA(nn.Module):\n#     def __init__(self, layer, rank=4):\n#         super(LoRA, self).__init__()\n#         self.layer = layer\n#         self.rank = rank\n#         self.lora_A = nn.Linear(layer.in_features, rank, bias=False)\n#         self.lora_B = nn.Linear(rank, layer.out_features, bias=False)\n#         nn.init.normal_(self.lora_A.weight, std=0.02)\n#         nn.init.normal_(self.lora_B.weight, std=0.02)\n        \n#     def forward(self, x):\n#         return self.layer(x) + self.lora_B(self.lora_A(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:00.913718Z","iopub.execute_input":"2024-11-19T12:11:00.914637Z","iopub.status.idle":"2024-11-19T12:11:00.919711Z","shell.execute_reply.started":"2024-11-19T12:11:00.914603Z","shell.execute_reply":"2024-11-19T12:11:00.918648Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# class GPT2WithLoRA(nn.Module):\n#     def __init__(self, config):\n#         super(GPT2WithLoRA, self).__init__()\n#         self.model = GPT2FromScratch(config)\n#         self.model.head = LoRA(self.model.head)\n\n#     def forward(self, x):\n#         logits = self.model(x)\n#         return {'logits': logits}  # Return a dictionary with logits\n\n#     def generate(self, input_ids, max_length=50, **kwargs):\n#         output = input_ids\n#         for _ in range(max_length):\n#             logits = self.forward(output)['logits']\n#             next_token = torch.argmax(logits[:, -1], dim=-1).unsqueeze(-1)\n#             output = torch.cat((output, next_token), dim=1)\n#         return output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:01.459779Z","iopub.execute_input":"2024-11-19T12:11:01.460566Z","iopub.status.idle":"2024-11-19T12:11:01.465014Z","shell.execute_reply.started":"2024-11-19T12:11:01.460534Z","shell.execute_reply":"2024-11-19T12:11:01.464221Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Create a tokenizer from scratch with custom vocab\ntokenizer = Tokenizer(models.WordLevel(vocab=custom_vocab_dict, unk_token=\"[UNK]\"))\nbase_tokenizer = AutoTokenizer.from_pretrained(\"roneneldan/TinyStories-1Layer-21M\")\n# Set up pre-tokenizer, normalizer, and decoder (as used in most tokenizers)\ntokenizer.normalizer = normalizers.Lowercase()\ntokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\ntokenizer.decoder = decoders.WordPiece()\n\n# Save the tokenizer to a file\ntokenizer.save(\"custom_tokenizer.json\")\n\n# Load this tokenizer into a PreTrainedTokenizerFast\ncustom_tokenizer = PreTrainedTokenizerFast(\n    tokenizer_file=\"custom_tokenizer.json\",\n    model_max_length=base_tokenizer.model_max_length\n)\n\n# Add special tokens if needed\ncustom_tokenizer.add_special_tokens({'additional_special_tokens': ['<sos>', '<eos>']})\ncustom_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n# Save the custom tokenizer\ncustom_tokenizer.save_pretrained(\"custom_tokenizer\")\n\n# Reload and print the vocabulary size to confirm\ncustom_tokenizer = AutoTokenizer.from_pretrained(\"custom_tokenizer\")\nprint(f\"Custom tokenizer vocabulary size: {custom_tokenizer.vocab_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:01.817002Z","iopub.execute_input":"2024-11-19T12:11:01.818176Z","iopub.status.idle":"2024-11-19T12:11:03.829552Z","shell.execute_reply.started":"2024-11-19T12:11:01.818119Z","shell.execute_reply":"2024-11-19T12:11:03.828644Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/722 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4e53827360b498dbf50c81698cd6b13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75ae3320e4344bcd8c14d86abebebe7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0b73bd86b364d8a88ef3d1d50943864"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147038001a3947d1a8456ecad672e913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdee591f0a174c4a86d6fd982f1f464f"}},"metadata":{}},{"name":"stdout","text":"Custom tokenizer vocabulary size: 9997\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Tokenization function for HuggingFace dataset\ndef tokenize_function(examples):\n    return custom_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=config['BLOCK_SIZE'])\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\nval_dataset = val_dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:03.938319Z","iopub.execute_input":"2024-11-19T12:11:03.938583Z","iopub.status.idle":"2024-11-19T12:11:25.301355Z","shell.execute_reply.started":"2024-11-19T12:11:03.938557Z","shell.execute_reply":"2024-11-19T12:11:25.300420Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/80000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e36dc44189c471087b3ef2267fa2fac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a623720d1eb4adea848f463180806e3"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Convert tokenized dataset to PyTorch tensors\ntrain_dataset.set_format(type='torch', columns=['input_ids'])\nval_dataset.set_format(type='torch', columns=['input_ids'])\n\ntrain_loader = data.DataLoader(train_dataset, batch_size=config['BATCH_SIZE'], shuffle=True)\nval_loader = data.DataLoader(val_dataset, batch_size=config['BATCH_SIZE'], shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:25.352609Z","iopub.execute_input":"2024-11-19T12:11:25.352871Z","iopub.status.idle":"2024-11-19T12:11:25.359978Z","shell.execute_reply.started":"2024-11-19T12:11:25.352845Z","shell.execute_reply":"2024-11-19T12:11:25.359137Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"print(len(custom_tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:25.361038Z","iopub.execute_input":"2024-11-19T12:11:25.361356Z","iopub.status.idle":"2024-11-19T12:11:25.424603Z","shell.execute_reply.started":"2024-11-19T12:11:25.361320Z","shell.execute_reply":"2024-11-19T12:11:25.423769Z"}},"outputs":[{"name":"stdout","text":"10000\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"model = GPT2FromScratch(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:25.426136Z","iopub.execute_input":"2024-11-19T12:11:25.426375Z","iopub.status.idle":"2024-11-19T12:11:25.725547Z","shell.execute_reply.started":"2024-11-19T12:11:25.426351Z","shell.execute_reply":"2024-11-19T12:11:25.724872Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model = model.to(config['DEVICE'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:25.726544Z","iopub.execute_input":"2024-11-19T12:11:25.726799Z","iopub.status.idle":"2024-11-19T12:11:25.905497Z","shell.execute_reply.started":"2024-11-19T12:11:25.726774Z","shell.execute_reply":"2024-11-19T12:11:25.904824Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total Parameters: {total_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:29.612055Z","iopub.execute_input":"2024-11-19T12:11:29.612857Z","iopub.status.idle":"2024-11-19T12:11:29.618796Z","shell.execute_reply.started":"2024-11-19T12:11:29.612824Z","shell.execute_reply":"2024-11-19T12:11:29.617931Z"}},"outputs":[{"name":"stdout","text":"Total Parameters: 8289552\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=config['LR'])\nloss_fn = torch.nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:30.645249Z","iopub.execute_input":"2024-11-19T12:11:30.645588Z","iopub.status.idle":"2024-11-19T12:11:31.279606Z","shell.execute_reply.started":"2024-11-19T12:11:30.645559Z","shell.execute_reply":"2024-11-19T12:11:31.278941Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"@torch.no_grad()\ndef eval_model(training_model: torch.nn.Module, val_loader: data.DataLoader):\n    training_model.eval()\n    losses = torch.zeros(config['EVAL_ITER'])\n    for k in range(config['EVAL_ITER']):\n        batch = next(iter(val_loader))\n        s_val = batch['input_ids'].to(config['DEVICE'])\n        t_val = s_val[:, 1:].clone()\n        s_val = s_val[:, :-1]\n        val_logits = training_model(s_val)\n        val_logits = val_logits.view(s_val.size(0) * s_val.size(1), config['VOCAB_SIZE'])\n        t_val = t_val.view(s_val.size(0) * s_val.size(1))\n        losses[k] = torch.nn.functional.cross_entropy(val_logits, t_val).item()\n    training_model.train()\n    return losses.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:31.713045Z","iopub.execute_input":"2024-11-19T12:11:31.713989Z","iopub.status.idle":"2024-11-19T12:11:31.720802Z","shell.execute_reply.started":"2024-11-19T12:11:31.713954Z","shell.execute_reply":"2024-11-19T12:11:31.719973Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, optimizer, config, loss_fn):\n    best_val_loss = float('inf')\n    patience_counter = 0\n    \n    try:\n        for epoch in range(config['EPOCHS']):\n            model.train()\n            epoch_loss = 0\n            epoch_progress = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{config['EPOCHS']}: \", leave=False)\n            \n            for b_idx, batch in enumerate(epoch_progress):\n                sources = batch['input_ids'].to(config['DEVICE'])\n                targets = sources[:, 1:].clone().to(config['DEVICE'])\n                sources = sources[:, :-1]\n                logits = model(sources)  # Direct tensor output\n                batch_size = sources.size(0)\n                seq_length = sources.size(1)\n                logits = logits.view(batch_size * seq_length, config['VOCAB_SIZE'])\n                targets = targets.view(batch_size * seq_length)\n                loss = loss_fn(logits, targets)\n                wandb.log({\"loss\": loss.item()})\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                epoch_loss += loss.item()\n                avg_loss = epoch_loss / (b_idx + 1)\n                epoch_progress.set_postfix(training_loss=avg_loss)\n\n            avg_epoch_loss = epoch_loss / len(train_loader)\n            print(f\"Epoch {epoch+1}/{config['EPOCHS']} completed with average training loss: {avg_epoch_loss}\")\n            \n            val_loss = eval_model(model, val_loader)\n            print(f\"Validation loss after {epoch+1} epochs: {val_loss}\")\n            wandb.log({\"val_loss\": val_loss})\n\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                patience_counter = 0\n                print(f\"New best validation loss: {val_loss}.\")\n            else:\n                patience_counter += 1\n                print(f\"No improvement in validation loss. Patience counter: {patience_counter}\")\n                \n            if patience_counter >= config['PATIENCE']:\n                print(\"Early stopping triggered.\")\n                break\n            \n    except KeyboardInterrupt:\n        print(\"Training interrupted.\")\n    print(\"Training completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:34.604523Z","iopub.execute_input":"2024-11-19T12:11:34.605107Z","iopub.status.idle":"2024-11-19T12:11:34.614265Z","shell.execute_reply.started":"2024-11-19T12:11:34.605074Z","shell.execute_reply":"2024-11-19T12:11:34.613417Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"if not load_model:\n    train_model(model, train_loader, val_loader, optimizer, config, loss_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:11:35.377115Z","iopub.execute_input":"2024-11-19T12:11:35.377928Z","iopub.status.idle":"2024-11-19T12:19:54.162933Z","shell.execute_reply.started":"2024-11-19T12:11:35.377884Z","shell.execute_reply":"2024-11-19T12:19:54.162101Z"}},"outputs":[{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 completed with average training loss: 3.6751812463760376\nValidation loss after 1 epochs: 3.4175243377685547\nNew best validation loss: 3.4175243377685547.\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5 completed with average training loss: 3.464756632709503\nValidation loss after 2 epochs: 3.3774402141571045\nNew best validation loss: 3.3774402141571045.\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5 completed with average training loss: 3.43430044965744\nValidation loss after 3 epochs: 3.3512024879455566\nNew best validation loss: 3.3512024879455566.\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5 completed with average training loss: 3.4177992327690125\nValidation loss after 4 epochs: 3.349935293197632\nNew best validation loss: 3.349935293197632.\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5 completed with average training loss: 3.4072976881980894\nValidation loss after 5 epochs: 3.3435232639312744\nNew best validation loss: 3.3435232639312744.\nTraining completed.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"model_req_path = config['WORKING_DIR']+'/model'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:19:54.164719Z","iopub.execute_input":"2024-11-19T12:19:54.165105Z","iopub.status.idle":"2024-11-19T12:19:54.169784Z","shell.execute_reply.started":"2024-11-19T12:19:54.165065Z","shell.execute_reply":"2024-11-19T12:19:54.168834Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"if not load_model:\n    if not os.path.exists(model_req_path):\n        os.mkdir(model_req_path)\n        \n    torch.save({'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict()\n                }, model_req_path+'/'+config['MODEL_NAME']+'.pt')\n\n    print(\"Model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:19:58.179256Z","iopub.execute_input":"2024-11-19T12:19:58.179600Z","iopub.status.idle":"2024-11-19T12:19:58.341388Z","shell.execute_reply.started":"2024-11-19T12:19:58.179569Z","shell.execute_reply":"2024-11-19T12:19:58.340585Z"}},"outputs":[{"name":"stdout","text":"Model saved!\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"if load_model and os.path.exists(model_req_path):\n    checkpoint = torch.load(model_req_path+'/'+config['MODEL_NAME']+'.pt', weights_only=True)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    print(\"Loaded the model!\")\nelif not os.path.exists(model_req_path):\n    print(\"Model directory not found! Please check the path.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:19:58.731775Z","iopub.execute_input":"2024-11-19T12:19:58.732148Z","iopub.status.idle":"2024-11-19T12:19:58.738108Z","shell.execute_reply.started":"2024-11-19T12:19:58.732115Z","shell.execute_reply":"2024-11-19T12:19:58.737244Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def prepare_input(text, tokenizer, device, block_size=128):\n    # Tokenize and encode the input text\n    inputs = tokenizer(\n        text, return_tensors=\"pt\", padding=\"max_length\",\n        truncation=True, max_length=block_size\n    )\n    # Move input tensors to the appropriate device\n    return {key: val.to(device) for key, val in inputs.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:19:59.593285Z","iopub.execute_input":"2024-11-19T12:19:59.593652Z","iopub.status.idle":"2024-11-19T12:19:59.599680Z","shell.execute_reply.started":"2024-11-19T12:19:59.593623Z","shell.execute_reply":"2024-11-19T12:19:59.598870Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def generate_text(model, tokenizer, input_text, config):\n    # Tokenize the input text\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(config[\"DEVICE\"])\n    \n    # Generate text using the model's `generate` method\n    output_ids = model.generate(\n        input_ids,\n        max_new_tokens=config['MAX_OUT_TOKENS']  # Max tokens to generate\n    )\n    \n    # Decode the generated IDs to text\n    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return generated_text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:20:00.662556Z","iopub.execute_input":"2024-11-19T12:20:00.663153Z","iopub.status.idle":"2024-11-19T12:20:00.668707Z","shell.execute_reply.started":"2024-11-19T12:20:00.663118Z","shell.execute_reply":"2024-11-19T12:20:00.667829Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def evaluate_text_gemini(generated_text):\n    # Use the generative model directly for evaluation\n    model2 = gemini_ai.GenerativeModel(\"gemini-1.5-flash\")\n    \n    # Generate content and get the response\n    response = model2.generate_content(generated_text, request_options=RequestOptions(retry=retry.Retry(initial=10, multiplier=2, maximum=60, timeout=500)))\n    \n    # Check if response contains valid content\n    if response.candidates:\n        eval_response = response.candidates[0].content.parts[0].text  # Get the text of the first candidate\n        return eval_response\n    else:\n        print(\"No valid candidates in the response. Check the generated text or API settings.\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:47:48.705029Z","iopub.execute_input":"2024-11-19T12:47:48.705834Z","iopub.status.idle":"2024-11-19T12:47:48.711936Z","shell.execute_reply.started":"2024-11-19T12:47:48.705801Z","shell.execute_reply":"2024-11-19T12:47:48.711161Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"input_texts_list = [\n    \"In a bustling city filled with secrets, a shadow loomed.\",\n    \"High in the mountains, a lone traveler braved the storm.\",\n    \"Beneath the waves, in a hidden underwater kingdom, life thrived.\",\n    \"It was a quiet night until the distant howls broke the silence.\",\n    \"In a world where dragons flew free, danger was never far.\",\n    \"On a small farm, a young girl discovered a mysterious egg.\",\n    \"In a town where everyone whispered, the new stranger caused a stir.\",\n    \"Under the light of the full moon, something magical began to stir.\",\n    \"In a time of peace, a hidden evil began to rise.\",\n    \"Amidst the golden sands of the desert, a lost caravan wandered.\",\n    \"In the heart of the enchanted forest, a hidden village thrived.\",\n    \"Aboard a ship sailing unknown seas, the crew faced a peculiar sight.\",\n    \"In a world where animals spoke, a young boy sought adventure.\",\n    \"Deep within the icy tundra, an ancient secret lay buried.\",\n    \"On a stormy night, a stranger knocked at the castle door.\",\n    \"In a village plagued by mysteries, a young detective took charge.\",\n    \"Across the galaxy, explorers marveled at a new world.\",\n    \"Underneath the quiet streets, a hidden society had formed.\",\n    \"Long ago, a powerful wizard disappeared without a trace.\",\n    \"At the edge of the world, a brave crew faced the unknown.\",\n    \"In a city that never slept, two souls crossed paths unexpectedly.\",\n    \"In a school for magical creatures, new students arrived.\",\n    \"Hidden in the clouds, a floating kingdom kept its secrets.\",\n    \"Far in the distant future, humanity encountered its first alien.\",\n    \"Under a blanket of stars, two friends made a promise.\",\n    \"In a library of forgotten books, a mysterious journal appeared.\",\n    \"Aboard a train that never stopped, secrets unraveled slowly.\",\n    \"Amid a sea of stars, a lone spaceship drifted in silence.\",\n    \"In a kingdom of snow and ice, a prophecy was foretold.\",\n    \"Deep in the jungle, explorers discovered a glowing stone.\",\n    \"In a village under a curse, a hero was born.\",\n    \"At the dawn of time, the first humans encountered magic.\",\n    \"On a distant moon, an outpost signaled for help.\",\n    \"In a quiet town, every night brought new mysteries.\",\n    \"Beneath the great pyramids, an ancient secret was uncovered.\",\n    \"In a world without color, a single red flower bloomed.\",\n    \"On a ship lost at sea, whispers of an island spread.\",\n    \"In the middle of nowhere, a door to another world appeared.\",\n    \"In a castle of mirrors, reflections began to act strangely.\",\n    \"On the edge of a cliff, a young prince made a fateful decision.\",\n    \"In a forest where time stood still, a visitor arrived.\",\n    \"In a kingdom ruled by animals, a lion declared his rule.\",\n    \"In a world where wishes came true, a girl wished for more time.\",\n    \"In a school where shadows came alive, mysteries abounded.\",\n    \"In a library that seemed endless, a strange book was found.\",\n    \"On a small island, villagers began to notice odd happenings.\",\n    \"In the great desert, a treasure was hidden for centuries.\",\n    \"In a city beneath the earth, a new ruler emerged.\",\n    \"In a world divided by seasons, an eternal summer began.\",\n    \"At the top of a mountain, a temple held the key to truth.\",\n    \"In a town where time rewound each day, mysteries deepened.\",\n    \"On a snowy peak, two climbers discovered an ancient statue.\",\n    \"In a mansion where paintings moved, a mystery unraveled.\",\n    \"At the crossroads of realms, two adventurers met.\",\n    \"In a school hidden in the woods, every student had a secret.\",\n    \"In a town of endless rain, hope was a rare sight.\",\n    \"On a train bound for nowhere, strange passengers arrived.\",\n    \"In a forest where trees whispered, a path emerged.\",\n    \"In a world where stars guided destiny, a comet foretold change.\",\n    \"In a lonely tower, a forgotten sorceress waited.\",\n    \"At the edge of a lake, the reflection showed another world.\",\n    \"In a world beneath the clouds, legends of the sky spread.\",\n    \"In a kingdom of night, a lone warrior sought dawn.\",\n    \"In a garden of eternal flowers, time stood still.\",\n    \"On an island that disappeared each night, a story began.\",\n    \"In a city that glittered like gold, shadows lurked.\",\n    \"In a land where dreams came alive, a nightmare was born.\",\n    \"On the longest night, a hero's journey began.\",\n    \"In a kingdom lost to time, an old legend resurfaced.\",\n    \"In a forest cloaked in fog, paths led nowhere.\",\n    \"In a small shop, a mysterious item granted wishes.\",\n    \"On the day the sun didn't rise, fear spread.\",\n    \"In a town with no maps, wanderers were welcome.\",\n    \"Under a sky of falling stars, two souls met.\",\n    \"In a house with endless rooms, a mystery unraveled.\",\n    \"In a town where no one aged, secrets were kept.\",\n    \"In the middle of the ocean, a floating castle appeared.\",\n    \"At the heart of the desert, a lone tree bloomed.\",\n    \"In a world ruled by music, silence was feared.\",\n    \"On the night of the festival, a strange guest arrived.\",\n    \"In a land where darkness ruled, a light began to shine.\",\n    \"In a city where everyone wore masks, truths hid.\",\n    \"In a world of whispers, silence was a power.\",\n    \"On the eve of battle, a hero was forged.\",\n    \"In a castle of glass, a kingdom looked on.\",\n    \"In the kingdom of echoes, a voice was heard.\",\n    \"In a forest where dreams came true, nightmares hid.\",\n    \"In a town with endless winters, a new day dawned.\",\n    \"In a realm where seasons changed daily, stories grew.\",\n    \"Under the gaze of ancient gods, mortals lived.\",\n    \"In a world frozen in time, a clock began to tick.\",\n    \"In a library of the lost, an old tale was read.\",\n    \"In a meadow under starlight, two friends found magic.\",\n    \"In a city where clocks ran backward, futures changed.\",\n    \"In a kingdom ruled by children, a new game began.\",\n    \"In a land where the moon never rose, stars told tales.\",\n    \"In the far north, where the aurora danced, legends lived.\",\n    \"At the edge of eternity, two lovers met.\",\n    \"In a village of music, silence brought fear.\",\n    \"In a world where memories could be traded, one boy remembered.\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:24:17.111767Z","iopub.execute_input":"2024-11-19T12:24:17.112102Z","iopub.status.idle":"2024-11-19T12:24:17.120813Z","shell.execute_reply.started":"2024-11-19T12:24:17.112073Z","shell.execute_reply":"2024-11-19T12:24:17.119884Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"pattern = r\"Grammar: (\\d+)/10; Consistency: (\\d+)/10; Creativity: (\\d+)/10; Plot: (\\d+)/10; Age group: ([A-Z])\"\nscore_list = []\ncount = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:51:24.632224Z","iopub.execute_input":"2024-11-19T12:51:24.633070Z","iopub.status.idle":"2024-11-19T12:51:24.637601Z","shell.execute_reply.started":"2024-11-19T12:51:24.633035Z","shell.execute_reply":"2024-11-19T12:51:24.636760Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"step_1_static = (\n    \"The following exercise, the student is given the beginning of a story. The student needs to complete it into a full story. \"\n    \"The exercise tests the student’s language abilities and creativity. The symbol * marks the separator between the \"\n    \"prescribed beginning and the student’s completion: \"\n)\n\nstep_2 = (\n    \"Please provide your general assessment about the part written by the student (the one after the * symbol). \"\n    \"Only give the ratings without description and overall could be omitted\"\n    \"Do not give explainations for the ratings.\"\n    \"Give them in one single line, separated by semi-colon.\"\n    \"Keep the fields for the output consistent, that is keep all the fields mentioned in the next sentence. \"\n    \"Grammer: ; Consistency: ; Creativity: ; Plot: ; Age group: \"\n    \"Is it grammatically correct? Is it consistent with the beginning of the story? Pay special attention to whether the \"\n    \"student manages to complete the sentence which is split in the middle by the separator *.\"\n)\n\nstep_3 = (\n    \"Now, grade the student’s completion in terms of grammar, creativity, consistency with the story’s beginning and \"\n    \"whether the plot makes sense. Moreover, please provide your best guess of what the age of the student might be, \"\n    \"as reflected from the completion. Choose from possible age groups: A: 3 or under. B: 4-5. C: 6-7. D: 8-9. E: 10-12. F: 13-16. \"\n    \"e.g. Grammar: 8/10; Consistency: 7/10; Creativity: 7/10; Plot: 7/10; Age group: E (10-12)\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:51:28.658168Z","iopub.execute_input":"2024-11-19T12:51:28.658525Z","iopub.status.idle":"2024-11-19T12:51:28.664333Z","shell.execute_reply.started":"2024-11-19T12:51:28.658494Z","shell.execute_reply":"2024-11-19T12:51:28.663479Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"if not load_df:\n    for input_text in input_texts_list:\n        output_text = generate_text(model, custom_tokenizer, input_text, config)\n        # print(output_text)\n        dynamic_part = f\"{input_text} Story begins here:*  {''.join(output_text)}. * The story ends here\"\n        final_prompt = f\"{step_1_static}{dynamic_part}\\n{step_2}\\n{step_3}\"\n        gemini_generated_response = evaluate_text_gemini(final_prompt)\n        print(gemini_generated_response)\n        gemini_generated_response = gemini_generated_response.strip()\n        count += 1\n        \n        # print(f\"{input_text}; {gemini_generated_response}\")\n        match = re.search(pattern, gemini_generated_response)\n        if match:\n            grammar, consistency, creativity, plot, age_group = match.groups()\n            score_list.append([input_text, int(grammar), int(consistency), int(creativity), age_group])\n        else:\n            score_list.append([input_text, 0, 0, 0, \"DNF\"])\n        print(f\"Number of prompts appended: {count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:51:31.049876Z","iopub.execute_input":"2024-11-19T12:51:31.050747Z"}},"outputs":[{"name":"stdout","text":"Grammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 1\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 2\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 3\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B (4-5)\n\nNumber of prompts appended: 4\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 5\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 6\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 7\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 8\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 9\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: E\n\nNumber of prompts appended: 10\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 11\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 12\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 13\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 14\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 15\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 16\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 17\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 18\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 19\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 20\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: B\n\nNumber of prompts appended: 21\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 22\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B (4-5)\n\nNumber of prompts appended: 23\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 24\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: B (4-5)\n\nNumber of prompts appended: 25\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 26\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 27\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 28\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 29\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 30\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 31\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 32\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 33\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 2/10; Age group: B\n\nNumber of prompts appended: 34\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B (4-5)\n\nNumber of prompts appended: 35\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 36\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 37\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 38\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B (4-5)\n\nNumber of prompts appended: 39\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 40\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 41\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 42\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 43\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 44\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 45\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 46\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 47\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: C\n\nNumber of prompts appended: 48\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B (4-5)\n\nNumber of prompts appended: 49\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 50\nGrammar: 3/10; Consistency: 2/10; Creativity: 4/10; Plot: 2/10; Age group: C\n\nNumber of prompts appended: 51\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 52\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B (4-5)\n\nNumber of prompts appended: 53\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: C\n\nNumber of prompts appended: 54\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 55\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: C (6-7)\n\nNumber of prompts appended: 56\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: E\n\nNumber of prompts appended: 57\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 58\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: C\n\nNumber of prompts appended: 59\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 60\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 61\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 62\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 63\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: C\n\nNumber of prompts appended: 64\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 65\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 2/10; Age group: B\n\nNumber of prompts appended: 66\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B (4-5)\n\nNumber of prompts appended: 67\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 68\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 69\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 70\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: B (4-5)\n\nNumber of prompts appended: 71\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 72\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 73\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: B\n\nNumber of prompts appended: 74\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: B (4-5)\n\nNumber of prompts appended: 75\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 76\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 77\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 78\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 79\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 80\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: B\n\nNumber of prompts appended: 81\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 82\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: B (4-5)\n\nNumber of prompts appended: 83\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 84\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 85\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: C\n\nNumber of prompts appended: 86\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 87\nGrammar: 4/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: C (6-7)\n\nNumber of prompts appended: 88\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: C\n\nNumber of prompts appended: 89\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 90\nGrammar: 3/10; Consistency: 2/10; Creativity: 3/10; Plot: 2/10; Age group: B\n\nNumber of prompts appended: 91\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 92\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 93\nGrammar: 2/10; Consistency: 1/10; Creativity: 3/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 94\nGrammar: 2/10; Consistency: 1/10; Creativity: 2/10; Plot: 1/10; Age group: B\n\nNumber of prompts appended: 95\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(score_list, columns=[\"Input Prompt\", \"Grammar\", \"Creativity\", \"Consistency\", \"Age Group\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result_req_path = config['WORKING_DIR']+'/result'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not load_df:\n    if not os.path.exists(result_req_path):\n        os.mkdir(result_req_path)\n        \n    df.to_pickle(result_req_path+'/'+'rating_df_'+config['MODEL_NAME']+'.pkl')\n\nprint(\"Dataframe saved!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if load_df and os.path.exists(result_req_path):\n    df = pd.read_pickle(result_req_path+'/'+'rating_df_'+config['MODEL_NAME']+'.pkl')\n    print(\"Loaded dataframe!\")\nelif not os.path.exists(result_req_path):\n    print(\"Result directory not found! Please check the path.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:09:48.118783Z","iopub.execute_input":"2024-11-17T15:09:48.119689Z","iopub.status.idle":"2024-11-17T15:10:00.208498Z","shell.execute_reply.started":"2024-11-17T15:09:48.119644Z","shell.execute_reply":"2024-11-17T15:10:00.207351Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"print(\"Modules in GPT2FromScratch model:\")\nfor name, module in model.named_modules():\n    print(name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:00.210436Z","iopub.execute_input":"2024-11-17T15:10:00.210785Z","iopub.status.idle":"2024-11-17T15:10:00.227180Z","shell.execute_reply.started":"2024-11-17T15:10:00.210744Z","shell.execute_reply":"2024-11-17T15:10:00.226161Z"}},"outputs":[{"name":"stdout","text":"Modules in GPT2FromScratch model:\n\nembeddings\nposition_embeddings\nblocks\nblocks.0\nblocks.0.self_attn\nblocks.0.self_attn.out_proj\nblocks.0.linear1\nblocks.0.dropout\nblocks.0.linear2\nblocks.0.norm1\nblocks.0.norm2\nblocks.0.dropout1\nblocks.0.dropout2\nblocks.1\nblocks.1.self_attn\nblocks.1.self_attn.out_proj\nblocks.1.linear1\nblocks.1.dropout\nblocks.1.linear2\nblocks.1.norm1\nblocks.1.norm2\nblocks.1.dropout1\nblocks.1.dropout2\nblocks.2\nblocks.2.self_attn\nblocks.2.self_attn.out_proj\nblocks.2.linear1\nblocks.2.dropout\nblocks.2.linear2\nblocks.2.norm1\nblocks.2.norm2\nblocks.2.dropout1\nblocks.2.dropout2\nblocks.3\nblocks.3.self_attn\nblocks.3.self_attn.out_proj\nblocks.3.linear1\nblocks.3.dropout\nblocks.3.linear2\nblocks.3.norm1\nblocks.3.norm2\nblocks.3.dropout1\nblocks.3.dropout2\nfinal_norm\nhead\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\n# Define LoRA configuration for specific attention submodules\nlora_config = LoraConfig(\n    r=4,\n    lora_alpha=16,\n    target_modules=[\n        \"blocks.0.self_attn.out_proj\",\n        \"blocks.1.self_attn.out_proj\",\n        \"blocks.2.self_attn.out_proj\",\n        \"blocks.3.self_attn.out_proj\",\n       \n    ],\n    bias=\"none\"\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:04.650632Z","iopub.execute_input":"2024-11-17T15:10:04.651554Z","iopub.status.idle":"2024-11-17T15:10:04.789804Z","shell.execute_reply.started":"2024-11-17T15:10:04.651507Z","shell.execute_reply":"2024-11-17T15:10:04.788878Z"}},"outputs":[{"name":"stdout","text":"trainable params: 8,192 || all params: 8,559,888 || trainable%: 0.0957\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    if not param.requires_grad:\n        print(f\"Parameter {name} does not require grad\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:06.242278Z","iopub.execute_input":"2024-11-17T15:10:06.242650Z","iopub.status.idle":"2024-11-17T15:10:06.261616Z","shell.execute_reply.started":"2024-11-17T15:10:06.242616Z","shell.execute_reply":"2024-11-17T15:10:06.260685Z"}},"outputs":[{"name":"stdout","text":"Parameter base_model.model.embeddings.weight does not require grad\nParameter base_model.model.position_embeddings.weight does not require grad\nParameter base_model.model.blocks.0.self_attn.in_proj_weight does not require grad\nParameter base_model.model.blocks.0.self_attn.in_proj_bias does not require grad\nParameter base_model.model.blocks.0.self_attn.out_proj.base_layer.weight does not require grad\nParameter base_model.model.blocks.0.self_attn.out_proj.base_layer.bias does not require grad\nParameter base_model.model.blocks.0.linear1.weight does not require grad\nParameter base_model.model.blocks.0.linear1.bias does not require grad\nParameter base_model.model.blocks.0.linear2.weight does not require grad\nParameter base_model.model.blocks.0.linear2.bias does not require grad\nParameter base_model.model.blocks.0.norm1.weight does not require grad\nParameter base_model.model.blocks.0.norm1.bias does not require grad\nParameter base_model.model.blocks.0.norm2.weight does not require grad\nParameter base_model.model.blocks.0.norm2.bias does not require grad\nParameter base_model.model.blocks.1.self_attn.in_proj_weight does not require grad\nParameter base_model.model.blocks.1.self_attn.in_proj_bias does not require grad\nParameter base_model.model.blocks.1.self_attn.out_proj.base_layer.weight does not require grad\nParameter base_model.model.blocks.1.self_attn.out_proj.base_layer.bias does not require grad\nParameter base_model.model.blocks.1.linear1.weight does not require grad\nParameter base_model.model.blocks.1.linear1.bias does not require grad\nParameter base_model.model.blocks.1.linear2.weight does not require grad\nParameter base_model.model.blocks.1.linear2.bias does not require grad\nParameter base_model.model.blocks.1.norm1.weight does not require grad\nParameter base_model.model.blocks.1.norm1.bias does not require grad\nParameter base_model.model.blocks.1.norm2.weight does not require grad\nParameter base_model.model.blocks.1.norm2.bias does not require grad\nParameter base_model.model.blocks.2.self_attn.in_proj_weight does not require grad\nParameter base_model.model.blocks.2.self_attn.in_proj_bias does not require grad\nParameter base_model.model.blocks.2.self_attn.out_proj.base_layer.weight does not require grad\nParameter base_model.model.blocks.2.self_attn.out_proj.base_layer.bias does not require grad\nParameter base_model.model.blocks.2.linear1.weight does not require grad\nParameter base_model.model.blocks.2.linear1.bias does not require grad\nParameter base_model.model.blocks.2.linear2.weight does not require grad\nParameter base_model.model.blocks.2.linear2.bias does not require grad\nParameter base_model.model.blocks.2.norm1.weight does not require grad\nParameter base_model.model.blocks.2.norm1.bias does not require grad\nParameter base_model.model.blocks.2.norm2.weight does not require grad\nParameter base_model.model.blocks.2.norm2.bias does not require grad\nParameter base_model.model.blocks.3.self_attn.in_proj_weight does not require grad\nParameter base_model.model.blocks.3.self_attn.in_proj_bias does not require grad\nParameter base_model.model.blocks.3.self_attn.out_proj.base_layer.weight does not require grad\nParameter base_model.model.blocks.3.self_attn.out_proj.base_layer.bias does not require grad\nParameter base_model.model.blocks.3.linear1.weight does not require grad\nParameter base_model.model.blocks.3.linear1.bias does not require grad\nParameter base_model.model.blocks.3.linear2.weight does not require grad\nParameter base_model.model.blocks.3.linear2.bias does not require grad\nParameter base_model.model.blocks.3.norm1.weight does not require grad\nParameter base_model.model.blocks.3.norm1.bias does not require grad\nParameter base_model.model.blocks.3.norm2.weight does not require grad\nParameter base_model.model.blocks.3.norm2.bias does not require grad\nParameter base_model.model.final_norm.weight does not require grad\nParameter base_model.model.final_norm.bias does not require grad\nParameter base_model.model.head.weight does not require grad\nParameter base_model.model.head.bias does not require grad\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"for name, module in model.named_modules():\n    if 'lora' in name:  # Or any specific identifier related to your LoRA layers\n        for param in module.parameters():\n            param.requires_grad = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:09.259139Z","iopub.execute_input":"2024-11-17T15:10:09.259542Z","iopub.status.idle":"2024-11-17T15:10:09.265314Z","shell.execute_reply.started":"2024-11-17T15:10:09.259496Z","shell.execute_reply":"2024-11-17T15:10:09.264303Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    if not param.requires_grad:\n        print(f\"Parameter {name} does not require grad\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:10.279549Z","iopub.execute_input":"2024-11-17T15:10:10.279950Z","iopub.status.idle":"2024-11-17T15:10:10.296829Z","shell.execute_reply.started":"2024-11-17T15:10:10.279900Z","shell.execute_reply":"2024-11-17T15:10:10.295783Z"}},"outputs":[{"name":"stdout","text":"Parameter base_model.model.embeddings.weight does not require grad\nParameter base_model.model.position_embeddings.weight does not require grad\nParameter base_model.model.blocks.0.self_attn.in_proj_weight does not require grad\nParameter base_model.model.blocks.0.self_attn.in_proj_bias does not require grad\nParameter base_model.model.blocks.0.self_attn.out_proj.base_layer.weight does not require grad\nParameter base_model.model.blocks.0.self_attn.out_proj.base_layer.bias does not require grad\nParameter base_model.model.blocks.0.linear1.weight does not require grad\nParameter base_model.model.blocks.0.linear1.bias does not require grad\nParameter base_model.model.blocks.0.linear2.weight does not require grad\nParameter base_model.model.blocks.0.linear2.bias does not require grad\nParameter base_model.model.blocks.0.norm1.weight does not require grad\nParameter base_model.model.blocks.0.norm1.bias does not require grad\nParameter base_model.model.blocks.0.norm2.weight does not require grad\nParameter base_model.model.blocks.0.norm2.bias does not require grad\nParameter base_model.model.blocks.1.self_attn.in_proj_weight does not require grad\nParameter base_model.model.blocks.1.self_attn.in_proj_bias does not require grad\nParameter base_model.model.blocks.1.self_attn.out_proj.base_layer.weight does not require grad\nParameter base_model.model.blocks.1.self_attn.out_proj.base_layer.bias does not require grad\nParameter base_model.model.blocks.1.linear1.weight does not require grad\nParameter base_model.model.blocks.1.linear1.bias does not require grad\nParameter base_model.model.blocks.1.linear2.weight does not require grad\nParameter base_model.model.blocks.1.linear2.bias does not require grad\nParameter base_model.model.blocks.1.norm1.weight does not require grad\nParameter base_model.model.blocks.1.norm1.bias does not require grad\nParameter base_model.model.blocks.1.norm2.weight does not require grad\nParameter base_model.model.blocks.1.norm2.bias does not require grad\nParameter base_model.model.blocks.2.self_attn.in_proj_weight does not require grad\nParameter base_model.model.blocks.2.self_attn.in_proj_bias does not require grad\nParameter base_model.model.blocks.2.self_attn.out_proj.base_layer.weight does not require grad\nParameter base_model.model.blocks.2.self_attn.out_proj.base_layer.bias does not require grad\nParameter base_model.model.blocks.2.linear1.weight does not require grad\nParameter base_model.model.blocks.2.linear1.bias does not require grad\nParameter base_model.model.blocks.2.linear2.weight does not require grad\nParameter base_model.model.blocks.2.linear2.bias does not require grad\nParameter base_model.model.blocks.2.norm1.weight does not require grad\nParameter base_model.model.blocks.2.norm1.bias does not require grad\nParameter base_model.model.blocks.2.norm2.weight does not require grad\nParameter base_model.model.blocks.2.norm2.bias does not require grad\nParameter base_model.model.blocks.3.self_attn.in_proj_weight does not require grad\nParameter base_model.model.blocks.3.self_attn.in_proj_bias does not require grad\nParameter base_model.model.blocks.3.self_attn.out_proj.base_layer.weight does not require grad\nParameter base_model.model.blocks.3.self_attn.out_proj.base_layer.bias does not require grad\nParameter base_model.model.blocks.3.linear1.weight does not require grad\nParameter base_model.model.blocks.3.linear1.bias does not require grad\nParameter base_model.model.blocks.3.linear2.weight does not require grad\nParameter base_model.model.blocks.3.linear2.bias does not require grad\nParameter base_model.model.blocks.3.norm1.weight does not require grad\nParameter base_model.model.blocks.3.norm1.bias does not require grad\nParameter base_model.model.blocks.3.norm2.weight does not require grad\nParameter base_model.model.blocks.3.norm2.bias does not require grad\nParameter base_model.model.final_norm.weight does not require grad\nParameter base_model.model.final_norm.bias does not require grad\nParameter base_model.model.head.weight does not require grad\nParameter base_model.model.head.bias does not require grad\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    if param.requires_grad is False:\n        param.requires_grad = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:13.381878Z","iopub.execute_input":"2024-11-17T15:10:13.382822Z","iopub.status.idle":"2024-11-17T15:10:13.387713Z","shell.execute_reply.started":"2024-11-17T15:10:13.382779Z","shell.execute_reply":"2024-11-17T15:10:13.386766Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    if not param.requires_grad:\n        print(f\"Parameter {name} does not require grad\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:14.387592Z","iopub.execute_input":"2024-11-17T15:10:14.388457Z","iopub.status.idle":"2024-11-17T15:10:14.393602Z","shell.execute_reply.started":"2024-11-17T15:10:14.388415Z","shell.execute_reply":"2024-11-17T15:10:14.392580Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total Parameters: {total_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:15.341954Z","iopub.execute_input":"2024-11-17T15:10:15.342838Z","iopub.status.idle":"2024-11-17T15:10:15.349345Z","shell.execute_reply.started":"2024-11-17T15:10:15.342797Z","shell.execute_reply":"2024-11-17T15:10:15.348372Z"}},"outputs":[{"name":"stdout","text":"Total Parameters: 8559888\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"train_model(model, train_loader, val_loader, optimizer, config, loss_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:10:16.429204Z","iopub.execute_input":"2024-11-17T15:10:16.429969Z","iopub.status.idle":"2024-11-17T15:17:20.235684Z","shell.execute_reply.started":"2024-11-17T15:10:16.429930Z","shell.execute_reply":"2024-11-17T15:17:20.234708Z"}},"outputs":[{"name":"stderr","text":"                                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 completed with average training loss: 0.02262271709293127\nValidation loss after 1 epochs: 0.02320951409637928\nNew best validation loss: 0.02320951409637928.\n","output_type":"stream"},{"name":"stderr","text":"                                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5 completed with average training loss: 0.020035073770210146\nValidation loss after 2 epochs: 0.023609422147274017\nNo improvement in validation loss. Patience counter: 1\n","output_type":"stream"},{"name":"stderr","text":"                                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5 completed with average training loss: 0.01763782303892076\nValidation loss after 3 epochs: 0.02494935318827629\nNo improvement in validation loss. Patience counter: 2\n","output_type":"stream"},{"name":"stderr","text":"                                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5 completed with average training loss: 0.015539395973458886\nValidation loss after 4 epochs: 0.027162861078977585\nNo improvement in validation loss. Patience counter: 3\nEarly stopping triggered.\nTraining completed.\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"if not load_df:\n    for input_text in input_texts_list:\n        output_text = generate_text(model, custom_tokenizer, input_text, config)\n        print(output_text)\n        dynamic_part = f\"{input_text} Story begins here:*  {''.join(output_text)}. * The story ends here\"\n        final_prompt = f\"{step_1_static}{dynamic_part}\\n{step_2}\\n{step_3}\"\n        gemini_generated_response = evaluate_text_gemini(final_prompt)\n        print(gemini_generated_response)\n        gemini_generated_response = gemini_generated_response.strip()\n        count += 1\n    \n        # print(f\"{input_text}; {gemini_generated_response}\")\n    \n        match = re.search(pattern, gemini_generated_response)\n        if match:\n            grammar, consistency, creativity, plot, age_group = match.groups()\n            score_list.append([input_text, int(grammar), int(consistency), int(creativity), age_group])\n        else:\n            score_list.append([input_text, 0, 0, 0, \"DNF\"])\n        print(f\"Number of prompts appended: {count}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1 = pd.DataFrame(score_list, columns=[\"Input Prompt\", \"Grammar\", \"Creativity\", \"Consistency\", \"Age Group\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:24:33.182729Z","iopub.execute_input":"2024-11-17T15:24:33.183379Z","iopub.status.idle":"2024-11-17T15:24:33.189316Z","shell.execute_reply.started":"2024-11-17T15:24:33.183341Z","shell.execute_reply":"2024-11-17T15:24:33.188225Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"result_req_path = config['WORKING_DIR']+'/result'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:24:34.119219Z","iopub.execute_input":"2024-11-17T15:24:34.119579Z","iopub.status.idle":"2024-11-17T15:24:34.123860Z","shell.execute_reply.started":"2024-11-17T15:24:34.119546Z","shell.execute_reply":"2024-11-17T15:24:34.122973Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"df1.to_pickle(result_req_path+'/'+'rating_df_LoRA'+config['MODEL_NAME']+'.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:24:36.835679Z","iopub.execute_input":"2024-11-17T15:24:36.836690Z","iopub.status.idle":"2024-11-17T15:24:36.841658Z","shell.execute_reply.started":"2024-11-17T15:24:36.836646Z","shell.execute_reply":"2024-11-17T15:24:36.840890Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"df1.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:24:37.735359Z","iopub.execute_input":"2024-11-17T15:24:37.736067Z","iopub.status.idle":"2024-11-17T15:24:37.747046Z","shell.execute_reply.started":"2024-11-17T15:24:37.736027Z","shell.execute_reply":"2024-11-17T15:24:37.746037Z"}},"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"                                        Input Prompt  Grammar  Creativity  \\\n0  In a bustling city filled with secrets, a shad...        0           0   \n1  High in the mountains, a lone traveler braved ...        0           0   \n2  Beneath the waves, in a hidden underwater king...        0           0   \n3  It was a quiet night until the distant howls b...        0           0   \n4  In a world where dragons flew free, danger was...        0           0   \n\n   Consistency Age Group  \n0            0       DNF  \n1            0       DNF  \n2            0         A  \n3            0       DNF  \n4            0       DNF  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Input Prompt</th>\n      <th>Grammar</th>\n      <th>Creativity</th>\n      <th>Consistency</th>\n      <th>Age Group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In a bustling city filled with secrets, a shad...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>High in the mountains, a lone traveler braved ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Beneath the waves, in a hidden underwater king...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>It was a quiet night until the distant howls b...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>In a world where dragons flew free, danger was...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":89},{"cell_type":"code","source":"df1.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:24:40.785293Z","iopub.execute_input":"2024-11-17T15:24:40.785897Z","iopub.status.idle":"2024-11-17T15:24:40.797223Z","shell.execute_reply.started":"2024-11-17T15:24:40.785858Z","shell.execute_reply":"2024-11-17T15:24:40.796204Z"}},"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"                                          Input Prompt  Grammar  Creativity  \\\n195  In a land where the moon never rose, stars tol...        0           0   \n196  In the far north, where the aurora danced, leg...        0           0   \n197           At the edge of eternity, two lovers met.        0           0   \n198       In a village of music, silence brought fear.        0           0   \n199  In a world where memories could be traded, one...        0           0   \n\n     Consistency Age Group  \n195            0       DNF  \n196            0         A  \n197            0         A  \n198            0       DNF  \n199            0       DNF  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Input Prompt</th>\n      <th>Grammar</th>\n      <th>Creativity</th>\n      <th>Consistency</th>\n      <th>Age Group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>In a land where the moon never rose, stars tol...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>In the far north, where the aurora danced, leg...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>At the edge of eternity, two lovers met.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>In a village of music, silence brought fear.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>In a world where memories could be traded, one...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":90},{"cell_type":"code","source":"model_req_path = config['WORKING_DIR']+'/model'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:24:43.741198Z","iopub.execute_input":"2024-11-17T15:24:43.741882Z","iopub.status.idle":"2024-11-17T15:24:43.746178Z","shell.execute_reply.started":"2024-11-17T15:24:43.741843Z","shell.execute_reply":"2024-11-17T15:24:43.745146Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"torch.save({'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict()\n                }, model_req_path+'/'+config['MODEL_NAME']+'LoRA'+'.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:24:44.241612Z","iopub.execute_input":"2024-11-17T15:24:44.242466Z","iopub.status.idle":"2024-11-17T15:24:44.403041Z","shell.execute_reply.started":"2024-11-17T15:24:44.242425Z","shell.execute_reply":"2024-11-17T15:24:44.402210Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"df1.head(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:24:45.158388Z","iopub.execute_input":"2024-11-17T15:24:45.159241Z","iopub.status.idle":"2024-11-17T15:24:45.171200Z","shell.execute_reply.started":"2024-11-17T15:24:45.159201Z","shell.execute_reply":"2024-11-17T15:24:45.170359Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"                                         Input Prompt  Grammar  Creativity  \\\n0   In a bustling city filled with secrets, a shad...        0           0   \n1   High in the mountains, a lone traveler braved ...        0           0   \n2   Beneath the waves, in a hidden underwater king...        0           0   \n3   It was a quiet night until the distant howls b...        0           0   \n4   In a world where dragons flew free, danger was...        0           0   \n5   On a small farm, a young girl discovered a mys...        0           0   \n6   In a town where everyone whispered, the new st...        0           0   \n7   Under the light of the full moon, something ma...        0           0   \n8    In a time of peace, a hidden evil began to rise.        0           0   \n9   Amidst the golden sands of the desert, a lost ...        0           0   \n10  In the heart of the enchanted forest, a hidden...        0           0   \n11  Aboard a ship sailing unknown seas, the crew f...        0           0   \n12  In a world where animals spoke, a young boy so...        0           0   \n13  Deep within the icy tundra, an ancient secret ...        0           0   \n14  On a stormy night, a stranger knocked at the c...        0           0   \n15  In a village plagued by mysteries, a young det...        0           0   \n16  Across the galaxy, explorers marveled at a new...        0           0   \n17  Underneath the quiet streets, a hidden society...        0           0   \n18  Long ago, a powerful wizard disappeared withou...        0           0   \n19  At the edge of the world, a brave crew faced t...        0           0   \n\n    Consistency Age Group  \n0             0       DNF  \n1             0       DNF  \n2             0         A  \n3             0       DNF  \n4             0       DNF  \n5             0       DNF  \n6             0       DNF  \n7             0       DNF  \n8             0       DNF  \n9             0         A  \n10            0         A  \n11            0       DNF  \n12            0       DNF  \n13            0         A  \n14            0       DNF  \n15            0       DNF  \n16            0       DNF  \n17            0       DNF  \n18            0       DNF  \n19            0       DNF  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Input Prompt</th>\n      <th>Grammar</th>\n      <th>Creativity</th>\n      <th>Consistency</th>\n      <th>Age Group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In a bustling city filled with secrets, a shad...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>High in the mountains, a lone traveler braved ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Beneath the waves, in a hidden underwater king...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>It was a quiet night until the distant howls b...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>In a world where dragons flew free, danger was...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>On a small farm, a young girl discovered a mys...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>In a town where everyone whispered, the new st...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Under the light of the full moon, something ma...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>In a time of peace, a hidden evil began to rise.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Amidst the golden sands of the desert, a lost ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>In the heart of the enchanted forest, a hidden...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Aboard a ship sailing unknown seas, the crew f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>In a world where animals spoke, a young boy so...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Deep within the icy tundra, an ancient secret ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>On a stormy night, a stranger knocked at the c...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>In a village plagued by mysteries, a young det...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Across the galaxy, explorers marveled at a new...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Underneath the quiet streets, a hidden society...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Long ago, a powerful wizard disappeared withou...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>At the edge of the world, a brave crew faced t...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>DNF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}